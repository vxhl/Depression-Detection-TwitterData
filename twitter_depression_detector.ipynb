{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Showcase : Twitter Depression Detection ðŸ™‚ðŸ•µï¸â€â™€ï¸\n",
    "I have taken an already collected and combined dataset from [swcwang/depression-detector](https://github.com/swcwang/depression-detection) since they were kind enough to open source a dataset for depression detection that they built and combined to get optimal results with their models\n",
    "\n",
    "> you can look over their Data Collection model [here](https://github.com/swcwang/depression-detection#collecting-data)\n",
    "\n",
    "Here I have used Torchtext, a Pytorch library for preprocessing of the twitter data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raze\\anaconda3\\lib\\site-packages\\tqdm\\std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import spacy # Advanced NLP library used for understanding systems and process text in Deep Learning\n",
    "from tqdm import tqdm_notebook,tnrange,tqdm # This makes our loops show a cool progress meter\n",
    "tqdm.pandas(desc='Progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchtext\n",
    "torchtext.__version__\n",
    "# TabularDataset : Defines a dataset of columns stored in CSV or other formats\n",
    "# BucketIterator : Defines an iterator that batches examples of similar lengths together.\n",
    "# Minimizes amount of padding needed while producing freshly shuffled batches for each new epoch. See pool for the bucketing procedure used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import re\n",
    "import string\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas version: 1.1.3\n",
      "Pytorch version: 1.8.1\n",
      "Torch Text version: 0.3.1\n",
      "Spacy version: 3.0.6\n"
     ]
    }
   ],
   "source": [
    "print('Python version:',sys.version)\n",
    "print('Pandas version:',pd.__version__)\n",
    "print('Pytorch version:', torch.__version__)\n",
    "print('Torch Text version:', torchtext.__version__)\n",
    "print('Spacy version:', spacy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading our Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tweets_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-0891b765a168>:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Today in Selfcare: beauty &amp;amp; laughs Kung Fu Panda 3 #Wellness #joy #laughter #selfcare #therapist #philadelphia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I get to spend New Year's home again alone and lonely. ???â€¢</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Depressed and lonely /: Stuck in a deep, never ending hole :(</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>If this is your response to someone saying they're dealing with , you're a terrible person.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Apparently you get a free pass just by mentioning    Where was I on the free badge day??!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0  0            \n",
       "1  1            \n",
       "2  2            \n",
       "3  3            \n",
       "4  4            \n",
       "\n",
       "                                                                                                                tweet  \\\n",
       "0  Today in Selfcare: beauty &amp; laughs Kung Fu Panda 3 #Wellness #joy #laughter #selfcare #therapist #philadelphia   \n",
       "1  I get to spend New Year's home again alone and lonely. ???â€¢                                                          \n",
       "2  Depressed and lonely /: Stuck in a deep, never ending hole :(                                                        \n",
       "3  If this is your response to someone saying they're dealing with , you're a terrible person.                          \n",
       "4  Apparently you get a free pass just by mentioning    Where was I on the free badge day??!!                           \n",
       "\n",
       "   target  \n",
       "0  0       \n",
       "1  1       \n",
       "2  1       \n",
       "3  0       \n",
       "4  0       "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pre Processing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for imbalance in our target variavle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2357\n",
       "1    843 \n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(5,3))\n",
    "ax = sns.barplot(x=df.target.unique(),y=df.target.value_counts());\n",
    "ax.set(xlabel='Labels');\n",
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.34375"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We get the percentage of different between our classes\n",
    "100 * (843/float(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.65625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * (2357/float(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we do not have a class imbalance situation with a split of approx 74:26 between our classes. \n",
    "> If it is only 70%-30% there is probably no need to balance the dataset. The class imbalance problem is caused by not having enough patterns for the minority class, rather than a high ratio of positive to negative patterns. Generally, if you have enough data, the \"class imbalance problem\" doesn't arise. Also, note that if you artificially balance the dataset, you are implying an equal prior probability of positive and negative patterns. If that isn't true, your model may give bad predictions by over-predicting the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    Today in Selfcare: beauty &amp; laughs Kung Fu Panda 3 #Wellness #joy #laughter #selfcare #therapist #philadelphia                              \n",
       " 1    I get to spend New Year's home again alone and lonely. ???â€¢                                                                                     \n",
       " 2    Depressed and lonely /: Stuck in a deep, never ending hole :(                                                                                   \n",
       " 3    If this is your response to someone saying they're dealing with , you're a terrible person.                                                     \n",
       " 4    Apparently you get a free pass just by mentioning    Where was I on the free badge day??!!                                                      \n",
       " 5    When you will never again give birth to violent men..   pic.twitter.com/pkdPhhlUuZ                                                              \n",
       " 6    Learning to pretend to have a good time had become a natural skill. I hope one day it is genuine                                                \n",
       " 7    Aw man im outta pizza rolls                                                                                                                     \n",
       " 8    When you go out and try to be a part of life & end up feeling like you are less a part of it then when you started.   pic.twitter.com/J625NXrWDb\n",
       " 9    So far he stop texting meâ€¦after I said somethingâ€¦so hopefully he doesn't show up at my houseâ€¦                                                   \n",
       " Name: tweet, dtype: object,\n",
       " 3190     is more closely associated with  than                                                                                                                                            \n",
       " 3191    At least @LewisHamilton not turning up is not the most outrageous thing at #F1Live #Kaiserchiefs                                                                                  \n",
       " 3192    Christmas without you     pic.twitter.com/IKzGhX6ZI8                                                                                                                              \n",
       " 3193    honestly just wanna watch OTH & have no Netflix to do that, so                                                                                                                    \n",
       " 3194    Depression is like wearing a one of those weighted blankets- makes it feel real good to lay in bed for 16 hours but also makes it pretty exhausting to do anything outside of that\n",
       " 3195    May the new year abound in Hâ€™s: Health, Hope, Healing, Happiness And H-coils!                                                                                                     \n",
       " 3196    It is not a beautiful day as usual.                                                                                                                                               \n",
       " 3197    Compact Metal Leaf Grinder with Four Layers  pic.twitter.com/VTan3PBT6H                                                                                                           \n",
       " 3198    First Christmas in YEARS that I have to work.  it just doesn't feel the same.                                                                                                     \n",
       " 3199    It's okay sus. Let that hurt go ðŸ¤— * that's me hugging ya bitter ass * ðŸ˜‚ðŸ˜‚ðŸ˜‚                                                                                                         \n",
       " Name: tweet, dtype: object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet.head(10), df.tweet.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for Non-Depressive Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Today in Selfcare: beauty &amp; laughs Kung Fu Panda 3 #Wellness #joy #laughter #selfcare #therapist #philadelphia\n",
       "3    If this is your response to someone saying they're dealing with , you're a terrible person.                       \n",
       "4    Apparently you get a free pass just by mentioning    Where was I on the free badge day??!!                        \n",
       "5    When you will never again give birth to violent men..   pic.twitter.com/pkdPhhlUuZ                                \n",
       "7    Aw man im outta pizza rolls                                                                                       \n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['target']==0].tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for Depressive tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     I get to spend New Year's home again alone and lonely. ???â€¢                                     \n",
       "2     Depressed and lonely /: Stuck in a deep, never ending hole :(                                   \n",
       "6     Learning to pretend to have a good time had become a natural skill. I hope one day it is genuine\n",
       "9     So far he stop texting meâ€¦after I said somethingâ€¦so hopefully he doesn't show up at my houseâ€¦   \n",
       "11    *sigh* ???? I haven't cried so muchâ€¦I'm in so much painâ€¦                                        \n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['target']==1].tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Defining Our Preprocessing Rules : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torchtext has problems handling \\n so first we need to remove them from our tweets and replace them with spaces. \n",
    "\n",
    "( This gave me a brief introduction into how regular expressions are used in modern NLP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3200/3200 [00:00<00:00, 266209.94it/s]\n"
     ]
    }
   ],
   "source": [
    "df['tweet'] = df.tweet.progress_apply(lambda x: re.sub('\\n', ' ', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our contraction dicts will gives context for the contracted words and separate them out into it's contextual meaning in the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_contractions(contraction_dict):\n",
    "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
    "    return contraction_dict, contraction_re\n",
    "\n",
    "contractions, contractions_re = _get_contractions(contraction_dict)\n",
    "\n",
    "def replace_contractions(text):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting and Removing abnormalies in our tweets\n",
    "Now we remove the unnecessary stuff from our tweets like URLs ( That may point towards advertisement ), Mentions ( That are most likely an anomaly case ), Emojis (Since they are random ), Hashtag symbols and Numbers. We also work on removing all symbols and punctuations expect for ., ! and ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_clean(text):\n",
    "    text = re.sub(r'https?:/\\/\\S+', ' ', text) # remove urls\n",
    "    text = re.sub(r'<([^>]*)>', ' ', text) # remove emojis\n",
    "    text = re.sub(r'@\\w+', ' ', text) # remove at mentions\n",
    "    text = re.sub(r'#', '', text) # remove hashtag symbol\n",
    "    text = re.sub(r'[0-9]+', ' ', text) # remove numbers\n",
    "    text = replace_contractions(text)\n",
    "    pattern = re.compile(r\"[ \\n\\t]+\")\n",
    "    text = pattern.sub(\" \", text)      \n",
    "    text = \"\".join(\"\".join(s)[:2] for _, s in itertools.groupby(text))    \n",
    "    text = re.sub(r'[^A-Za-z0-9,?.!]+', ' ', text) # remove all symbols and punctuation except for . , ! and ?\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we tokenize our tweets using spacy by making `tweet_clean(s)` as an `nlp` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\",disable=['lemmatizer', 'tagger', 'ner'])\n",
    "def tokenizer(s): return [w.text.lower() for w in nlp(tweet_clean(s))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining fields\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The field object takes arguments on how to process the tokenized text.\n",
    "\n",
    "This field object will later be attached to the dataset -> `train_val-field`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the fields for our tweets \n",
    "TEXT = Field(sequential=True, tokenize=tokenizer, include_lengths=True, use_vocab = True)\n",
    "# We define the fields for our target variable. It does not need any tokenization since it is already in it's class form of 1s and 0s\n",
    "TARGET = Field(sequential=False, use_vocab=False, pad_token=None, unk_token=None, is_target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we assign our fields to our dataset\n",
    "data_fields = [\n",
    "    (None, None),\n",
    "    (\"tweet\", TEXT), \n",
    "    (\"target\", TARGET)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building our Train-Val-Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was honestly pretty confused on the significant differences between a test and validation datasets,\n",
    "\n",
    "So I referred to this insanely dedicated article to have a better understanding for them. \n",
    "https://machinelearningmastery.com/difference-test-validation-datasets/#:~:text=%E2%80%93%20Validation%20set%3A%20A%20set%20of,of%20a%20fully%2Dspecified%20classifier.&text=These%20are%20the%20recommended%20definitions%20and%20usages%20of%20the%20terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Suppose that we would like to estimate the test error associated with fitting a particular statistical learning method on a set of observations. The validation set approach [â€¦] is a very simple strategy for this task. It involves randomly dividing the available set of observations into two parts, a training set and a validation set or hold-out set. The model is fit on the training set, and the fitted model is used to predict the responses for the observations in the validation set. The resulting validation set error rate â€” typically assessed using MSE in the case of a quantitative responseâ€”provides an estimate of the test error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-split -> 80:20\n",
    "from sklearn.model_selection import train_test_split\n",
    "def splitting_train_test(df, test_size = 0.2):\n",
    "    train, val = train_test_split(df, test_size=test_size, random_state = 42)\n",
    "    return train.reset_index(drop=True), val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation set \n",
    "train_val, test = splitting_train_test(df, test_size=0.2)\n",
    "train, val = splitting_train_test(train_val, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\", index=False)\n",
    "val.to_csv(\"val.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2048, 3), (512, 3), (640, 3))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us plot the newly created datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Labels'), Text(0, 0.5, 'counts'), Text(0.5, 1.0, 'test')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,4))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "ax = fig.add_subplot(1,3,1)\n",
    "ax = sns.barplot(x=train.target.unique(),y=train.target.value_counts())\n",
    "ax.set(xlabel='Labels', ylabel=\"counts\", title=\"train\")\n",
    "\n",
    "ax1 = fig.add_subplot(1,3,2)\n",
    "ax1 = sns.barplot(x=val.target.unique(),y=val.target.value_counts())\n",
    "ax1.set(xlabel='Labels', ylabel=\"counts\", title=\"validation\")\n",
    "\n",
    "ax2 = fig.add_subplot(1,3,3)\n",
    "ax2 = sns.barplot(x=test.target.unique(),y=test.target.value_counts())\n",
    "ax2.set(xlabel='Labels', ylabel=\"counts\", title=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting to our train-val-test into `TabularDataset` for torchtext operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data, val_data, test_data = TabularDataset.splits(path='./', format='csv', train='train.csv', validation='val.csv', test='test.csv', fields=data_fields, skip_header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Loading our Vector embeddings and `build_vocab`\n",
    "Torchtext makes loading of pretrained word vectors very easy. Just mention the name of the pretrained word vector (e.g. glove.6B.50d, fasttext.en.300d, etc.) and torchtext will download that particular vector and then you can use it in embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 622 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MAX_VOCAB_SIZE = 100_000\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE,\n",
    "                 vectors=\"glove.6B.50d\")\n",
    "\n",
    "TARGET.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5470, 50])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.dataset.TabularDataset at 0x223a03d5730>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Loading Data in Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the BucketIterator to access the Dataloader. It sorts data according to length of text, and groups similar length text in a batch, thus reducing the amount of padding required. It pads the batch according to the max length in that particular batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = BucketIterator.splits(datasets=(train_data, val_data, test_data), \n",
    "                                            batch_sizes=(3,3,3), \n",
    "                                            sort_key=lambda x: len(x.tweet),         # Used to order text sequences in batches\n",
    "                                            device=None,                             \n",
    "                                            sort_within_batch=True, \n",
    "                                            repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 171, 214)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically iter() calls the __iter__() method on the `train_loader` which returns an iterator. next() then calls the __next__() method on that iterator to get the first iteration. Running next() again will get the second item of the iterator, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.data.batch.Batch"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  48,    4,  530],\n",
       "         [  56,  107,  318],\n",
       "         [ 119,  145,   10],\n",
       "         [ 312,   63,   24],\n",
       "         [  40,    6,   72],\n",
       "         [  31, 2255,   45],\n",
       "         [   9, 1437,   10],\n",
       "         [1431,    2,  114]]),\n",
       " tensor([8, 8, 8]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> . ? i\n"
     ]
    }
   ],
   "source": [
    "print (TEXT.vocab.itos[1],\n",
    "TEXT.vocab.itos[2],\n",
    "TEXT.vocab.itos[3],\n",
    "TEXT.vocab.itos[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idxtosent(batch, idx):\n",
    "    return ' '.join([TEXT.vocab.itos[i] for i in batch.tweet[0][:,idx].cpu().data.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no one ever looks happy on a bus   i did nt get the ariana calendar .   awe thanks you so much love you too\n"
     ]
    }
   ],
   "source": [
    "print(idxtosent(batch,0),\" \",idxtosent(batch,1),\" \", idxtosent(batch,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 3,\n",
       " 'dataset': <torchtext.data.dataset.TabularDataset at 0x223a03d5730>,\n",
       " 'fields': dict_keys([None, 'tweet', 'target']),\n",
       " 'input_fields': ['tweet', 'target'],\n",
       " 'target_fields': [],\n",
       " 'tweet': (tensor([[  48,    4,  530],\n",
       "          [  56,  107,  318],\n",
       "          [ 119,  145,   10],\n",
       "          [ 312,   63,   24],\n",
       "          [  40,    6,   72],\n",
       "          [  31, 2255,   45],\n",
       "          [   9, 1437,   10],\n",
       "          [1431,    2,  114]]),\n",
       "  tensor([8, 8, 8])),\n",
       " 'target': tensor([0, 0, 0])}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let us define the BatchGenerator class. \n",
    "Most important components in a PyTorch Dataset class are:\n",
    "__len__(self, ) where it returns the number of examples in our dataset that we read in __init__(self, ).\n",
    "\n",
    "This will ensure that len() will return the number of examples.\n",
    "\n",
    "The __iter__() function returns an iterator for the given object (array, set, tuple etc. or custom objects). It creates an object that can be accessed one element at a time using __next__() function, which generally comes in handy when dealing with loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, dl, x_field, y_field):\n",
    "        # data loading\n",
    "        self.dl, self.x_field, self.y_field = dl, x_field, y_field\n",
    "        \n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            X = getattr(batch, self.x_field)\n",
    "            y = getattr(batch, self.y_field)\n",
    "            yield (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[ 106,   56,   40],\n",
       "          [  11,   60,  173],\n",
       "          [  24,  224, 1376],\n",
       "          [ 696,   17,   13],\n",
       "          [  13, 2999,    4],\n",
       "          [  35,   79,   98],\n",
       "          [3966,   20,   84],\n",
       "          [  19,   83,   92],\n",
       "          [ 299, 1205,   67],\n",
       "          [  13,    3,  131],\n",
       "          [ 676,    3,  173]]),\n",
       "  tensor([11, 11, 11])),\n",
       " tensor([0, 0, 0]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch_it = BatchGenerator(train_loader, 'tweet', 'target')\n",
    "next(iter(train_batch_it)) # We define a training batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model training I followed the example in https://medium.com/@sonicboom8/sentiment-analysis-torchtext-55fb57b1fab8 along with some more studies from the https://github.com/swcwang/depression-detection who made small modifications by adding dropouts to lessen overfitting.\n",
    "\n",
    "Our mode uses a pretrained embedding layer from glove that we imported using torchtext, a bidirecetional GRU and a concat pooling method where we perform average pool and max pool and then concatenate the results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
